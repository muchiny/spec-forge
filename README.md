# ğŸ”¨ spec-forge

> **Transforme tes User Stories en SpÃ©cifications et Tests Gherkin/BDD automatiquement, grÃ¢ce Ã  l'IA locale.**

[![Rust](https://img.shields.io/badge/Rust-1.85+-orange?logo=rust)](https://www.rust-lang.org/)
[![Ollama](https://img.shields.io/badge/LLM-Ollama-blue?logo=ollama)](https://ollama.com/)
[![License: MIT](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

---

## ğŸ¯ C'est quoi spec-forge ?

**spec-forge** est un outil CLI en Rust qui automatise le passage des **User Stories** aux **tests BDD/Gherkin**, en passant par des **spÃ©cifications raffinÃ©es** â€” le tout pilotÃ© par un LLM local (Ollama).

ğŸ’¡ **L'idÃ©e** : reproduire le workflow dÃ©crit dans l'article [*"De la User Story Ã  l'exÃ©cution automatique des tests"*](https://latavernedutesteur.fr/2026/02/18/de-la-user-story-a-lexecution-automatique-des-tests-jai-teste-un-workflow-ia-dans-jira-rovo-xray-lynqa/) â€” mais **gratuitement, en interne, sans dÃ©pendance SaaS** (Jira, Rovo, Xray, Lynqa).

| Workflow SaaS (article) | spec-forge (local & gratuit) |
|---|---|
| ğŸ¢ Jira (User Stories) | ğŸ“„ Fichiers Markdown / YAML |
| ğŸ¤– Rovo (amÃ©liore les US) | `spec-forge refine` + Ollama |
| ğŸ§ª Xray (gÃ©nÃ¨re les tests) | `spec-forge generate-tests` + Ollama |
| ğŸ“Š Jira (traÃ§abilitÃ©) | Matrice de traÃ§abilitÃ© auto-gÃ©nÃ©rÃ©e |

---

## ğŸš€ Pipeline en un coup d'Å“il

```mermaid
graph LR
    A["ğŸ“ User Stories<br/><i>.md / .yaml</i>"] -->|spec-forge refine| B["ğŸ“‹ SpÃ©cifications<br/><i>raffinÃ©es .md</i>"]
    B -->|spec-forge generate-tests| C["ğŸ§ª Tests Gherkin<br/><i>.feature</i>"]
    C --> D["ğŸ“Š Matrice de<br/>traÃ§abilitÃ©"]

    style A fill:#4CAF50,stroke:#333,color:#fff
    style B fill:#2196F3,stroke:#333,color:#fff
    style C fill:#FF9800,stroke:#333,color:#fff
    style D fill:#9C27B0,stroke:#333,color:#fff
```

### ğŸ” DÃ©tail du pipeline

```mermaid
flowchart TD
    subgraph "ğŸ“¥ EntrÃ©e"
        US["ğŸ“ User Stories<br/>Markdown ou YAML"]
    end

    subgraph "ğŸ”§ Ã‰tape 1 â€” Raffinement"
        R1["ğŸ“– Lecture & parsing<br/>des User Stories"]
        R2["ğŸ§  LLM (Ollama)<br/>+ template refine_system"]
        R3["âœ… Validation<br/>complÃ©tude & clartÃ©"]
        R4["ğŸ“‹ SpÃ©cification raffinÃ©e<br/>format spec-kit"]
        R1 --> R2 --> R3 --> R4
    end

    subgraph "ğŸ§ª Ã‰tape 2 â€” GÃ©nÃ©ration de tests"
        G1["ğŸ“– Lecture de la<br/>spÃ©cification"]
        G2["ğŸ§  LLM (Ollama)<br/>+ template generate_tests_system"]
        G3["âœ… Validation<br/>syntaxe Gherkin"]
        G4["ğŸ“„ Fichiers .feature<br/>+ traÃ§abilitÃ©"]
        G1 --> G2 --> G3 --> G4
    end

    US --> R1
    R4 --> G1

    style US fill:#4CAF50,stroke:#333,color:#fff
    style R2 fill:#2196F3,stroke:#333,color:#fff
    style G2 fill:#2196F3,stroke:#333,color:#fff
    style R4 fill:#FF9800,stroke:#333,color:#fff
    style G4 fill:#9C27B0,stroke:#333,color:#fff
```

---

## ğŸ“¦ Installation

### PrÃ©requis

| Outil | Version | RÃ´le |
|---|---|---|
| ğŸ¦€ **Rust** | â‰¥ 1.85 | Compilation du projet |
| ğŸ¤– **Ollama** | latest | LLM local (gratuit) |
| ğŸ§  **qwen2.5:7b** | â€” | ModÃ¨le IA recommandÃ© |

### Ã‰tapes

```bash
# 1. Cloner le projet
git clone https://github.com/votre-org/spec-forge.git
cd spec-forge

# 2. Compiler
cargo build --release

# 3. Installer Ollama (si pas dÃ©jÃ  fait)
curl -fsSL https://ollama.com/install.sh | sh

# 4. TÃ©lÃ©charger le modÃ¨le recommandÃ©
ollama pull qwen2.5:7b

# 5. VÃ©rifier que tout fonctionne
cargo run -- check
```

âœ… Si tout est OK, vous devriez voir :

```
>> Verification de la connexion LLM...
   Provider: ollama, Modele: qwen2.5:7b, URL: http://localhost:11434
OK Ollama est accessible
OK Modele 'qwen2.5:7b' disponible
```

---

## ğŸ® Utilisation

### âš¡ Pipeline complet (recommandÃ©)

```bash
# User Stories â†’ SpÃ©cifications â†’ Tests Gherkin en une seule commande
spec-forge pipeline --input mes_user_stories.md --output output/
```

### ğŸ”§ Ã‰tapes individuelles

```bash
# Ã‰tape 1 : Raffiner les User Stories en spÃ©cification
spec-forge refine --input user_stories.md --output output/specs/

# Ã‰tape 2 : GÃ©nÃ©rer les tests Gherkin depuis une spec
spec-forge generate-tests --spec output/specs/spec.md --output output/features/

# VÃ©rifier la connexion au LLM
spec-forge check
```

### ğŸ“ Format d'entrÃ©e : User Stories en Markdown

```markdown
# User Stories - Mon Projet

## Recherche par ISBN

En tant que bibliothÃ©caire, je veux rechercher un livre par ISBN
afin de trouver rapidement un ouvrage spÃ©cifique.

- Le champ de saisie accepte les formats ISBN-10 et ISBN-13
- Les rÃ©sultats s'affichent en moins de 2 secondes
- Si l'ISBN n'existe pas, un message clair est affichÃ©

## Inscription en ligne

En tant que futur adhÃ©rent, je veux m'inscrire en ligne
afin de pouvoir emprunter des livres sans me dÃ©placer.

- Le formulaire demande nom, prÃ©nom, email et adresse
- Un email de confirmation est envoyÃ© automatiquement
```

### ğŸ“¤ RÃ©sultat gÃ©nÃ©rÃ©

Ã€ partir de 3 User Stories, spec-forge produit automatiquement :

| Sortie | Description |
|---|---|
| ğŸ“‹ `output/specs/spec-*.md` | SpÃ©cification raffinÃ©e (scÃ©narios, exigences, entitÃ©s, cas limites) |
| ğŸ§ª `output/features/*.feature` | Fichiers Gherkin/BDD avec tags de traÃ§abilitÃ© |
| ğŸ“Š `output/traceability.md` | Matrice de traÃ§abilitÃ© (FR â†’ US â†’ ScÃ©narios) |

**Exemple de sortie Gherkin :**

```gherkin
# language: fr

@US-002 @P1
Fonctionnalite: Recherche d'un livre par ISBN pour le bibliothecaire

  @happy_path @FR-002
  Plan du Scenario: Recherche d'un livre par ISBN valide
    Soit Un utilisateur est sur l'interface de recherche
    Quand il saisit un ISBN valide (ISBN-10 ou ISBN-13)
    Alors les rÃ©sultats s'affichent en moins de 2 secondes

    Exemples:
      | isbn |
      | 978-3-16-148410-0 |
      | 0-521-63285-6 |
```

---

## ğŸ—ï¸ Architecture

spec-forge suit une **architecture hexagonale** (ports & adapters) pour garantir modularitÃ© et testabilitÃ©.

```mermaid
graph TB
    subgraph "ğŸ¯ Domaine"
        US["UserStory"]
        SP["Specification"]
        TC["Feature / Scenario"]
        VA["Validation"]
    end

    subgraph "ğŸ”Œ Ports (interfaces)"
        P1["LlmService"]
        P2["InputReader"]
        P3["OutputWriter"]
        P4["TemplateEngine"]
    end

    subgraph "ğŸ”§ Adapters (implÃ©mentations)"
        A1["OllamaAdapter"]
        A2["MarkdownReader<br/>YamlReader"]
        A3["MarkdownWriter<br/>GherkinWriter<br/>TraceabilityWriter"]
        A4["FileTemplateEngine<br/>(Handlebars)"]
    end

    subgraph "âš™ï¸ Application"
        SVC1["RefineService"]
        SVC2["GenerateTestsService"]
        PIP["Pipeline"]
    end

    subgraph "ğŸ–¥ï¸ Infrastructure"
        CFG["Config (YAML)"]
        LOG["Logging (tracing)"]
        CLI["CLI (clap)"]
    end

    P1 -.-> A1
    P2 -.-> A2
    P3 -.-> A3
    P4 -.-> A4

    PIP --> SVC1
    PIP --> SVC2
    SVC1 --> P1
    SVC1 --> P4
    SVC2 --> P1
    SVC2 --> P4
    PIP --> P2
    PIP --> P3

    CLI --> PIP
    CFG --> CLI

    style US fill:#4CAF50,stroke:#333,color:#fff
    style SP fill:#4CAF50,stroke:#333,color:#fff
    style TC fill:#4CAF50,stroke:#333,color:#fff
    style VA fill:#4CAF50,stroke:#333,color:#fff
    style PIP fill:#FF9800,stroke:#333,color:#fff
```

---

## ğŸ“ Structure du projet

```
spec-forge/
â”œâ”€â”€ ğŸ“„ Cargo.toml                        # DÃ©pendances Rust
â”œâ”€â”€ âš™ï¸ config.yaml                       # Configuration par dÃ©faut
â”œâ”€â”€ ğŸ“ templates/                         # Prompts LLM (Handlebars)
â”‚   â”œâ”€â”€ refine_system.md                  # System prompt : raffinement
â”‚   â”œâ”€â”€ refine_user.md                    # User prompt : raffinement
â”‚   â”œâ”€â”€ generate_tests_system.md          # System prompt : gÃ©nÃ©ration tests
â”‚   â””â”€â”€ generate_tests_user.md            # User prompt : gÃ©nÃ©ration tests
â”œâ”€â”€ ğŸ“š examples/
â”‚   â””â”€â”€ user_stories/
â”‚       â””â”€â”€ sample_us.md                  # Exemple de User Stories
â”œâ”€â”€ ğŸ¦€ src/
â”‚   â”œâ”€â”€ main.rs                           # Point d'entrÃ©e CLI
â”‚   â”œâ”€â”€ lib.rs                            # RÃ©-exports modules
â”‚   â”œâ”€â”€ domain/                           # ğŸ¯ ModÃ¨les mÃ©tier
â”‚   â”‚   â”œâ”€â”€ user_story.rs                 # UserStory, Priority, Language
â”‚   â”‚   â”œâ”€â”€ specification.rs              # Specification, FunctionalRequirement
â”‚   â”‚   â”œâ”€â”€ test_case.rs                  # Feature, Scenario, Step (Gherkin)
â”‚   â”‚   â”œâ”€â”€ errors.rs                     # Erreurs domaine (thiserror)
â”‚   â”‚   â””â”€â”€ validation.rs                 # RÃ¨gles de validation
â”‚   â”œâ”€â”€ ports/                            # ğŸ”Œ Interfaces (traits)
â”‚   â”‚   â”œâ”€â”€ llm_service.rs                # Trait LlmService
â”‚   â”‚   â”œâ”€â”€ input_reader.rs               # Trait InputReader
â”‚   â”‚   â”œâ”€â”€ output_writer.rs              # Trait OutputWriter
â”‚   â”‚   â””â”€â”€ template_engine.rs            # Trait TemplateEngine
â”‚   â”œâ”€â”€ adapters/                         # ğŸ”§ ImplÃ©mentations
â”‚   â”‚   â”œâ”€â”€ llm/
â”‚   â”‚   â”‚   â”œâ”€â”€ ollama_adapter.rs         # Adapter Ollama (HTTP/JSON)
â”‚   â”‚   â”‚   â””â”€â”€ mock_adapter.rs           # Mock pour tests
â”‚   â”‚   â”œâ”€â”€ input/
â”‚   â”‚   â”‚   â”œâ”€â”€ markdown_reader.rs        # Parse US depuis Markdown
â”‚   â”‚   â”‚   â””â”€â”€ yaml_reader.rs            # Parse US depuis YAML
â”‚   â”‚   â”œâ”€â”€ output/
â”‚   â”‚   â”‚   â”œâ”€â”€ markdown_writer.rs        # Ã‰crit specs Markdown
â”‚   â”‚   â”‚   â”œâ”€â”€ gherkin_writer.rs         # Ã‰crit fichiers .feature
â”‚   â”‚   â”‚   â””â”€â”€ traceability_writer.rs    # Matrice de traÃ§abilitÃ©
â”‚   â”‚   â””â”€â”€ templates/
â”‚   â”‚       â””â”€â”€ file_template_engine.rs   # Charge templates Handlebars
â”‚   â”œâ”€â”€ application/                      # âš™ï¸ Services applicatifs
â”‚   â”‚   â”œâ”€â”€ pipeline.rs                   # Orchestrateur du pipeline
â”‚   â”‚   â”œâ”€â”€ refine_service.rs             # US â†’ Spec (via LLM)
â”‚   â”‚   â””â”€â”€ generate_tests_service.rs     # Spec â†’ Gherkin (via LLM)
â”‚   â””â”€â”€ infrastructure/                   # ğŸ–¥ï¸ Configuration & logging
â”‚       â”œâ”€â”€ config.rs                     # Chargement config YAML
â”‚       â””â”€â”€ logging.rs                    # Setup tracing
â””â”€â”€ ğŸ“¤ output/                            # RÃ©sultats gÃ©nÃ©rÃ©s
    â”œâ”€â”€ specs/                            # SpÃ©cifications raffinÃ©es
    â”œâ”€â”€ features/                         # Fichiers .feature
    â””â”€â”€ traceability.md                   # Matrice de traÃ§abilitÃ©
```

---

## âš™ï¸ Configuration

Le fichier `config.yaml` permet de personnaliser le comportement :

```yaml
# ğŸ¤– LLM
llm:
  provider: "ollama"              # Provider IA
  model_name: "qwen2.5:7b"       # ModÃ¨le (gratuit, local)
  api_base_url: "http://localhost:11434"
  temperature: 0.1                # Basse = plus dÃ©terministe

# ğŸŒ Langue
pipeline:
  default_language: "fr"          # fr ou en
output:
  gherkin_language: "fr"          # Mots-clÃ©s Gherkin en franÃ§ais

# âœ… Validation
validation:
  min_coverage_percent: 80        # Couverture minimale exigÃ©e
  validate_gherkin_syntax: true   # Valider la syntaxe .feature
  max_clarifications: 3           # Max ambiguÃ¯tÃ©s signalÃ©es
```

---

## ğŸ› ï¸ Stack technique

| Composant | Technologie | RÃ´le |
|---|---|---|
| ğŸ¦€ Langage | **Rust** (edition 2024) | Performance, sÃ©curitÃ© mÃ©moire |
| ğŸ¤– LLM | **Ollama** + **Qwen2.5:7b** | IA locale, gratuite |
| ğŸ“¡ HTTP | **reqwest** | Communication avec l'API Ollama |
| ğŸ–¥ï¸ CLI | **clap** | Interface ligne de commande |
| ğŸ“ Templates | **Handlebars** | Prompts LLM dynamiques |
| ğŸ§ª Gherkin | **gherkin** (crate) | Validation syntaxe BDD |
| ğŸ“„ Markdown | **pulldown-cmark** | Parsing des entrÃ©es Markdown |
| âš™ï¸ Config | **config** + **serde_yaml** | Configuration YAML layered |
| ğŸ” Logging | **tracing** | Logs structurÃ©s |
| ğŸ¨ Terminal | **console** + **indicatif** | Couleurs et barres de progression |

---

## ğŸŒ Support multi-langue

spec-forge supporte le **franÃ§ais** ğŸ‡«ğŸ‡· et l'**anglais** ğŸ‡¬ğŸ‡§ pour :

- ğŸ“ **L'entrÃ©e** : User Stories en `"En tant que..."` ou `"As a..."`
- ğŸ“‹ **Les spÃ©cifications** : Sortie dans la langue dÃ©tectÃ©e
- ğŸ§ª **Le Gherkin** : Mots-clÃ©s franÃ§ais (`Soit`/`Quand`/`Alors`) ou anglais (`Given`/`When`/`Then`)

---

## ğŸ“Š TraÃ§abilitÃ©

Chaque artefact gÃ©nÃ©rÃ© conserve la **traÃ§abilitÃ© complÃ¨te** via des tags :

```mermaid
graph LR
    US["ğŸ·ï¸ @US-002<br/>User Story"] --> FR["ğŸ·ï¸ @FR-002<br/>Exigence fonctionnelle"]
    FR --> SC["ğŸ·ï¸ @happy_path<br/>ScÃ©nario Gherkin"]

    style US fill:#4CAF50,stroke:#333,color:#fff
    style FR fill:#2196F3,stroke:#333,color:#fff
    style SC fill:#FF9800,stroke:#333,color:#fff
```

La **matrice de traÃ§abilitÃ©** auto-gÃ©nÃ©rÃ©e identifie :
- âœ… Les exigences **couvertes** par des scÃ©narios
- âš ï¸ Les **GAPs** (exigences sans test correspondant)
- ğŸ“ˆ Le **taux de couverture** global

---

## ğŸ¤ Inspirations

- ğŸ“˜ [**spec-kit**](https://github.com/github/spec-kit) â€” MÃ©thodologie Spec-Driven Development (SDD) par GitHub
- ğŸ“° [**La Taverne du Testeur**](https://latavernedutesteur.fr/2026/02/18/de-la-user-story-a-lexecution-automatique-des-tests-jai-teste-un-workflow-ia-dans-jira-rovo-xray-lynqa/) â€” Article sur le workflow IA (Rovo + Xray + Lynqa)
- ğŸ—ï¸ **mcp-doc-rag** â€” Architecture hexagonale Rust et OllamaAdapter rÃ©utilisÃ©s

---

## ğŸ“œ Licence

MIT â€” Libre d'utilisation, modification et distribution.
